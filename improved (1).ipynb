{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYnZHkLhMrtc",
    "outputId": "e3ae3dc7-96b7-4cb7-9640-4005e9dc69b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.13.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.11.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch->timm)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.2.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 timm-0.9.16\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdkedFNnwSg8",
    "outputId": "23b88cab-ecc2-40d2-bbfb-f3493a89172c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/841.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/841.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.7/841.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m839.7/841.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.4)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.11.2 torchmetrics-1.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "F7PiOa8kCUIJ"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "from google.colab import drive\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import timm\n",
    "from timm import create_model\n",
    "from torchmetrics.image import TotalVariation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YQHFYc0iyorv"
   },
   "outputs": [],
   "source": [
    "#Data extraction and cleanup code in unused jupiter notebook in repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bsd5nC9OM4PL",
    "outputId": "663dcce0-7651-4a3f-be6e-1a399929bdec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')\n",
    "content_images = []\n",
    "style_images = []\n",
    "content_path = '/content/drive/MyDrive/CV2/coco_styleprocessed'\n",
    "style_path = '/content/drive/MyDrive/CV2/styleprocessed'\n",
    "content_temp = glob.glob(content_path + '/*.jpg')\n",
    "style_temp = glob.glob(style_path + '/*.jpg')\n",
    "\n",
    "for file in content_temp[:10]:\n",
    "    image = cv2.imread(file)\n",
    "    content_images.append(image)\n",
    "\n",
    "for file in style_temp[:10]:\n",
    "    image = cv2.imread(file)\n",
    "    style_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "id": "8xE9e-fP0TMi"
   },
   "outputs": [],
   "source": [
    "c_num=1\n",
    "s_num=3\n",
    "\n",
    "content1 = content_temp[c_num]\n",
    "style1 = style_temp[s_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Hn4sj7z6zJQH"
   },
   "outputs": [],
   "source": [
    "content_image = cv2.imread(content1)\n",
    "style_image = cv2.imread(style1)\n",
    "content_image_rgb = cv2.cvtColor(content_image, cv2.COLOR_BGR2RGB)\n",
    "style_image_rgb = cv2.cvtColor(style_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(content_image_rgb)\n",
    "plt.title('Content Image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(style_image_rgb)\n",
    "plt.title('Style Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4vFvjc-a1iud",
    "outputId": "77f127f3-c5a6-4afd-f22f-eef1e66e8593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "vgg = models.vgg19(pretrained=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "vgg = nn.Sequential(*list(vgg.features.children())[:36]).to(device)\n",
    "vgg.eval()\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "# print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "id": "e8jVAcne8zCt"
   },
   "outputs": [],
   "source": [
    "#Calc additional loss terms\n",
    "vit_model = create_model('vit_base_patch16_224', pretrained=True, img_size=256)\n",
    "vit_model = vit_model.to(device)\n",
    "vit_model.eval()\n",
    "tv_loss = TotalVariation().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "c9HSMx1C81Hk"
   },
   "outputs": [],
   "source": [
    "def get_features(model, input, layers):\n",
    "    out = {}\n",
    "    temp = input\n",
    "    for i, conv2d in enumerate(model.children()):\n",
    "        temp = conv2d(temp)\n",
    "        if i in layers:\n",
    "            out[i] = temp\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fzrYnLrYht1p"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(input):\n",
    "    b, c, h, w = input.size()\n",
    "    input = input.view(b * c, h * w)\n",
    "    G = torch.mm(input, input.t())\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "TO1Q6PKAM0N1"
   },
   "outputs": [],
   "source": [
    "content_open = Image.open(content1)\n",
    "style_open = Image.open(style1)\n",
    "\n",
    "transf = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "content_image = transf(content_open).unsqueeze(0).to(device)\n",
    "style_image = transf(style_open).unsqueeze(0).to(device)\n",
    "\n",
    "#check printed layers, later layers have high noise\n",
    "content_layers = [0, 2]\n",
    "style_layers = [2, 5, 7]\n",
    "#2,5,7 has good perf if the output is the content image. .01lr .001 weight 2000 iter\n",
    "# previously tried 2,5,12 and 2, 12, 21\n",
    "\n",
    "content_features = []\n",
    "style_features = []\n",
    "\n",
    "content_features = get_features(vgg, content_image, content_layers)\n",
    "style_features = get_features(vgg, style_image, style_layers)\n",
    "\n",
    "out = content_image.clone().detach().requires_grad_(True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oOaysvAfxpmd",
    "outputId": "104090c9-e74e-4a69-e35a-525d1618cf5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Content Loss = 0.0, Style Loss = 1824760576.0, VIT Loss = 0.0, TV Loss = 64061.984375\n",
      "Iteration 100: Content Loss = 0.9412723779678345, Style Loss = 66273344.0, VIT Loss = 6.6143717765808105, TV Loss = 113794.2734375\n",
      "Iteration 200: Content Loss = 1.1305432319641113, Style Loss = 20774612.0, VIT Loss = 7.671840667724609, TV Loss = 118252.703125\n",
      "Iteration 300: Content Loss = 1.2198402881622314, Style Loss = 11261599.0, VIT Loss = 8.115427017211914, TV Loss = 120676.0703125\n",
      "Iteration 400: Content Loss = 1.277691125869751, Style Loss = 7021936.0, VIT Loss = 8.437158584594727, TV Loss = 122151.0546875\n",
      "Iteration 500: Content Loss = 1.3205711841583252, Style Loss = 4761596.0, VIT Loss = 8.804503440856934, TV Loss = 123004.46875\n",
      "Iteration 600: Content Loss = 1.3542883396148682, Style Loss = 3455680.0, VIT Loss = 9.111523628234863, TV Loss = 123399.1875\n",
      "Iteration 700: Content Loss = 1.3818424940109253, Style Loss = 2636185.25, VIT Loss = 9.339530944824219, TV Loss = 123462.1875\n",
      "Iteration 800: Content Loss = 1.4052766561508179, Style Loss = 2089607.875, VIT Loss = 9.497429847717285, TV Loss = 123285.3515625\n",
      "Iteration 900: Content Loss = 1.4254251718521118, Style Loss = 1705458.25, VIT Loss = 9.669692039489746, TV Loss = 122921.1875\n",
      "Iteration 1000: Content Loss = 1.4431556463241577, Style Loss = 1422554.5, VIT Loss = 9.791172981262207, TV Loss = 122421.53125\n",
      "Iteration 1100: Content Loss = 1.4578561782836914, Style Loss = 1212998.5, VIT Loss = 9.925301551818848, TV Loss = 121106.59375\n",
      "Iteration 1200: Content Loss = 1.4713436365127563, Style Loss = 1048882.125, VIT Loss = 10.046369552612305, TV Loss = 119798.625\n",
      "Iteration 1300: Content Loss = 1.4836565256118774, Style Loss = 917835.4375, VIT Loss = 10.142135620117188, TV Loss = 118512.765625\n",
      "Iteration 1400: Content Loss = 1.4950103759765625, Style Loss = 811253.9375, VIT Loss = 10.224959373474121, TV Loss = 117246.8125\n",
      "Iteration 1500: Content Loss = 1.5056109428405762, Style Loss = 723582.375, VIT Loss = 10.296152114868164, TV Loss = 116007.0546875\n",
      "Iteration 1600: Content Loss = 1.5154528617858887, Style Loss = 650392.625, VIT Loss = 10.35671615600586, TV Loss = 114786.71875\n",
      "Iteration 1700: Content Loss = 1.524695873260498, Style Loss = 588199.4375, VIT Loss = 10.407196998596191, TV Loss = 113592.1875\n",
      "Iteration 1800: Content Loss = 1.533514142036438, Style Loss = 535019.75, VIT Loss = 10.452820777893066, TV Loss = 112427.234375\n",
      "Iteration 1900: Content Loss = 1.5420355796813965, Style Loss = 488922.5625, VIT Loss = 10.483441352844238, TV Loss = 111301.28125\n"
     ]
    }
   ],
   "source": [
    "#Pick initializer\n",
    "optimizer = optim.Adam([out], lr=0.01)\n",
    "# Target is for content loss to be close to 1\n",
    "# start with output = content, 1000-2000 iter lr .01 sweight .001\n",
    "iter = 2000\n",
    "\n",
    "# Track loss over each iteration\n",
    "content_losses = []\n",
    "style_losses = []\n",
    "vit_losses = []\n",
    "var_losses = []\n",
    "total_losses = []\n",
    "\n",
    "for i in range(iter):\n",
    "    content_weight = 0.5\n",
    "    style_weight = 0.001\n",
    "    vit_weight = 0.1\n",
    "    #.001 to .005 all work okay, depends on the photo. May have to try running 4000-5000\n",
    "    if i > (iter-1000):\n",
    "      tv_weight = .015\n",
    "    else:\n",
    "      tv_weight = .01\n",
    "\n",
    "    # Extract features for content and style layers\n",
    "    content_output_features = get_features(vgg, out, content_layers)\n",
    "    style_output_features = get_features(vgg, out, style_layers)\n",
    "\n",
    "    content_loss = 0.0\n",
    "    style_loss = 0.0\n",
    "\n",
    "    #content, sum of MSE(output, content features) for layers\n",
    "    for layer_idx in content_layers:\n",
    "        content_loss += F.mse_loss(content_output_features[layer_idx], content_features[layer_idx])\n",
    "\n",
    "    #style, sum of MSE(Gram matrix of output, Gram matrix of style features) for layers\n",
    "    for layer_idx in style_layers:\n",
    "        gram = gram_matrix(style_features[layer_idx])\n",
    "        gram_out = gram_matrix(style_output_features[layer_idx])\n",
    "        style_loss += F.mse_loss(gram_out, gram)\n",
    "\n",
    "    #VIT\n",
    "    content_vit_features = vit_model.forward_features(content_image)\n",
    "    output_vit_features = vit_model.forward_features(out)\n",
    "    vit_loss = F.mse_loss(output_vit_features, content_vit_features)\n",
    "    #TV\n",
    "    var_loss = tv_loss(out)\n",
    "    \n",
    "    total_loss = content_weight * content_loss + style_weight * style_loss + vit_weight * vit_loss + tv_weight * var_loss\n",
    "    content_losses.append(content_loss.item())\n",
    "    style_losses.append(style_loss.item())\n",
    "    vit_losses.append(vit_loss.item())\n",
    "    var_losses.append(var_loss.item())\n",
    "    total_losses.append(total_loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i}: Content Loss = {content_loss.item()}, Style Loss = {style_loss.item()}, VIT Loss = {vit_loss.item()}, TV Loss = {var_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "UvtVsrAm0Nrw"
   },
   "outputs": [],
   "source": [
    "#save\n",
    "temp = out\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(device)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(device)\n",
    "temp = temp * std + mean\n",
    "output_img = temp.cpu().clone().detach().squeeze(0)\n",
    "output_img = transforms.ToPILImage()(output_img)\n",
    "# os.remove(\"output_image.jpg\")\n",
    "# output_img.save(\"output_image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2WfHCHnzNF_"
   },
   "source": [
    "# Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "id": "Dt_Tw7aczXTn"
   },
   "outputs": [],
   "source": [
    "print(\"Style: \", s_num)\n",
    "print(\"Content: \", c_num)\n",
    "print(\"Iterations: \", iter)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "#content\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(content_image_rgb)\n",
    "plt.title('Content Image')\n",
    "plt.axis('off')\n",
    "\n",
    "#style\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(style_image_rgb)\n",
    "plt.title('Style Image')\n",
    "plt.axis('off')\n",
    "\n",
    "#out\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(output_img)\n",
    "plt.title('Output Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RG5V5Ee041Qu",
    "outputId": "93c938f5-2067-4a06-9dde-6a58eff7b8f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Content Fidelity Score: 1.5502350330352783\n",
      "Final Style Accuracy Score: 5.45808092056177e-08\n",
      "Final Overall Aesthetic Score: 0.7751175165176392\n"
     ]
    }
   ],
   "source": [
    "def content_fidelity_score(content_features, generated_features, content_layers):\n",
    "    content_loss = 0.0\n",
    "    for layer in content_layers:\n",
    "        content_loss += F.mse_loss(generated_features[layer], content_features[layer])\n",
    "    return content_loss\n",
    "\n",
    "def style_accuracy_score(style_features, generated_features, style_layers):\n",
    "    style_loss = 0.0\n",
    "    for layer in style_layers:\n",
    "        gram_style = gram_matrix(style_features[layer])\n",
    "        gram_generated = gram_matrix(generated_features[layer])\n",
    "        style_loss += F.mse_loss(gram_generated, gram_style)\n",
    "    return style_loss\n",
    "\n",
    "def overall_aesthetic_score(content_score, style_score, alpha=0.5, beta=0.5):\n",
    "    return alpha * content_score + beta * style_score\n",
    "\n",
    "final_content_features = get_features(vgg, out, content_layers)\n",
    "final_style_features = get_features(vgg, out, style_layers)\n",
    "\n",
    "final_content_fidelity = content_fidelity_score(content_features, final_content_features, content_layers)\n",
    "final_style_accuracy = style_accuracy_score(style_features, final_style_features, style_layers)\n",
    "final_overall_aesthetic = overall_aesthetic_score(final_content_fidelity, final_style_accuracy)\n",
    "\n",
    "print(f\"Final Content Fidelity Score: {final_content_fidelity.item()}\")\n",
    "print(f\"Final Style Accuracy Score: {final_style_accuracy.item()}\")\n",
    "print(f\"Final Overall Aesthetic Score: {final_overall_aesthetic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "id": "sYxmhI587-vH"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "#content\n",
    "plt.subplot(5, 1, 1)\n",
    "plt.plot(content_losses, label='Content Loss', color='blue')\n",
    "plt.title('Content Loss over Iterations')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Content Loss')\n",
    "plt.legend()\n",
    "\n",
    "#style\n",
    "plt.subplot(5, 1, 2)\n",
    "plt.plot(style_losses, label='Style Loss', color='blue')\n",
    "plt.title('Style Loss over Iterations')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Style Loss')\n",
    "plt.legend()\n",
    "\n",
    "#transf\n",
    "plt.subplot(5, 1, 3)\n",
    "plt.plot(vit_losses, label='VIT Loss', color='blue')\n",
    "plt.title('VIT Loss over Iterations')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('VIT Loss')\n",
    "plt.legend()\n",
    "\n",
    "#tv\n",
    "plt.subplot(5, 1, 4)\n",
    "plt.plot(vit_losses, label='Total Variation Loss', color='blue')\n",
    "plt.title('Total Variation Loss over Iterations')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Total Variation Loss')\n",
    "plt.legend()\n",
    "\n",
    "#total\n",
    "plt.subplot(5, 1, 5)\n",
    "plt.plot(total_losses, label='Total Loss', color='blue')\n",
    "plt.title('Total Loss over Iterations')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(f\"Final Content Fidelity Score: {final_content_fidelity.item()}\")\n",
    "print(f\"Final Style Accuracy Score: {final_style_accuracy.item()}\")\n",
    "print(f\"Final Overall Aesthetic Score: {final_overall_aesthetic}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
